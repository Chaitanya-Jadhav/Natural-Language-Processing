{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT STRING: The snow was coming down in big heavy flakes now.She greeted them with a big smile, hugging each of them as if they were old friends she hadn't seen in a decade.\n"
     ]
    }
   ],
   "source": [
    "input_string=\"The snow was coming down in big heavy flakes now.\"\\\n",
    "            +\"She greeted them with a big smile, hugging each of them as \" \\\n",
    "            +\"if they were old friends she hadn't seen in a decade.\"\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "WORDS=tokenizer.tokenize(input_string.lower())\n",
    "print(\"INPUT STRING:\",input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------------+\n",
      "| Sr. No |  Token  | Stemmed Token |\n",
      "+--------+---------+---------------+\n",
      "|   0    |   the   |      the      |\n",
      "|   1    |   snow  |      snow     |\n",
      "|   2    |   was   |       wa      |\n",
      "|   3    |  coming |      come     |\n",
      "|   4    |   down  |      down     |\n",
      "|   5    |    in   |       in      |\n",
      "|   6    |   big   |      big      |\n",
      "|   7    |  heavy  |     heavi     |\n",
      "|   8    |  flakes |     flake     |\n",
      "|   9    |   now   |      now      |\n",
      "|   10   |   she   |      she      |\n",
      "|   11   | greeted |     greet     |\n",
      "|   12   |   them  |      them     |\n",
      "|   13   |   with  |      with     |\n",
      "|   14   |    a    |       a       |\n",
      "|   15   |   big   |      big      |\n",
      "|   16   |  smile  |     smile     |\n",
      "|   17   | hugging |      hug      |\n",
      "|   18   |   each  |      each     |\n",
      "|   19   |    of   |       of      |\n",
      "|   20   |   them  |      them     |\n",
      "|   21   |    as   |       as      |\n",
      "|   22   |    if   |       if      |\n",
      "|   23   |   they  |      they     |\n",
      "|   24   |   were  |      were     |\n",
      "|   25   |   old   |      old      |\n",
      "|   26   | friends |     friend    |\n",
      "|   27   |   she   |      she      |\n",
      "|   28   |   hadn  |      hadn     |\n",
      "|   29   |    t    |       t       |\n",
      "|   30   |   seen  |      seen     |\n",
      "|   31   |    in   |       in      |\n",
      "|   32   |    a    |       a       |\n",
      "|   33   |  decade |     decad     |\n",
      "+--------+---------+---------------+\n"
     ]
    }
   ],
   "source": [
    "pt=PrettyTable()\n",
    "pt.field_names=[\"Sr. No\",\"Token\",\"Stemmed Token\"]\n",
    "ps=PorterStemmer()\n",
    "for i in range(0,len(WORDS)):\n",
    "    pt.add_row([i,WORDS[i],ps.stem(WORDS[i])])\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
